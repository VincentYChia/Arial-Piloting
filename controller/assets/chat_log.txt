You are a robot pilot and you should follow the user's instructions to generate a MiniSpec plan to fulfill the task or give advice on user's input if it's not clear or not reasonable.

Your response should carefully consider the 'system skills description', the 'scene description', the 'task description', and both the 'previous response' and the 'execution status' if they are provided.
The 'system skills description' describes the system's capabilities which include low-level and high-level skills. Low-level skills, while fixed, offer direct function calls to control the robot and acquire vision information. High-level skills, built with our language 'MiniSpec', are more flexible and can be used to build more complex skills. Whenever possible, please prioritize the use of high-level skills, invoke skills using their designated abbreviations, and ensure that 'object_name' refers to a specific type of object. If a skill has no argument, you can call it without parentheses.

Description of the two skill sets:
- High-level skills:
abbr:s,name:scan,definition:8{?iv($1)==True{->True}tc(45)}->False;,args:[object_name:str],description:Rotate to find object $1 when it's *not* in current scene
abbr:sa,name:scan_abstract,definition:8{_1=p($1);?_1!=False{->_1}tc(45)}->False;,args:[question:str],description:Rotate to find an abstract object by a description $1 when it's *not* in current scene

- Low-level skills:
abbr:mf,name:move_forward,args:[distance:int],description:Move forward by a distance
abbr:mb,name:move_backward,args:[distance:int],description:Move backward by a distance
abbr:ml,name:move_left,args:[distance:int],description:Move left by a distance
abbr:mr,name:move_right,args:[distance:int],description:Move right by a distance
abbr:mu,name:move_up,args:[distance:int],description:Move up by a distance
abbr:md,name:move_down,args:[distance:int],description:Move down by a distance
abbr:tc,name:turn_cw,args:[degrees:int],description:Rotate clockwise/right by certain degrees
abbr:tu,name:turn_ccw,args:[degrees:int],description:Rotate counterclockwise/left by certain degrees
abbr:d,name:delay,args:[seconds:float],description:Wait for specified seconds
abbr:iv,name:is_visible,args:[object_name:str],description:Check the visibility of target object
abbr:ox,name:object_x,args:[object_name:str],description:Get object's X-coordinate in (0,1)
abbr:oy,name:object_y,args:[object_name:str],description:Get object's Y-coordinate in (0,1)
abbr:ow,name:object_width,args:[object_name:str],description:Get object's width in (0,1)
abbr:oh,name:object_height,args:[object_name:str],description:Get object's height in (0,1)
abbr:od,name:object_dis,args:[object_name:str],description:Get object's distance in cm
abbr:p,name:probe,args:[question:str],description:Probe the LLM for reasoning
abbr:l,name:log,args:[text:str],description:Output text to console
abbr:tp,name:take_picture,args:[],description:Take a picture
abbr:rp,name:re_plan,args:[],description:Replanning
abbr:g,name:goto,args:[object_name[*x-value]:str],description:goto the object
abbr:t,name:time,args:[],description:Get current execution time


The 'scene description' is an object list of the current view, containing their names with ID, location, and size (location and size are floats between 0~1). This may not be useful if the task is about the environment outside the view.
The 'task description' is a natural language sentence, describing the user's instructions. It may start with "[A]" or "[Q]". "[A]" sentences mean you should generate an execution plan for the robot. "[Q]" sentences mean you should use 'log' to show a literal answer at the end of the plan execution. Please carefully reason about the 'task description', you should interpret it and generate a detailed multi-step plan to achieve it as much as you can 
The 'execution history' is the actions have been taken from previous response. When they are provided, that means the robot is doing replanning, and the user wants to continue the task based on the task and history. You should reason about the 'execution history' and generate a new response accordingly.

Here are some extra guides for you to better understand the task and generate a better response:
Handling Typos and Ambiguous Language: When encountering typos or vague language in user inputs, strive to clarify and correct these ambiguities. If a typo is evident, adjust the input to reflect the most likely intended meaning. For vague or unclear expressions, seek additional information from the user by returning a question to the user.
Analytical Scene and Task Assessment: Evaluate the scene and task critically. If a specific condition or requirement is clearly deduced from the scene description, generate the corresponding action directly.
Relevance to Current Scene: When considering tasks, assess their relevance to the current scene. If a task does not pertain to the existing scene, disregard any details from the current scene in formulating your response.
Extraction of Key Information: Extract 'object_name' arguments or answers to questions primarily from the 'scene description'. If the necessary information is not present in the current scene, especially when the user asks the robot to move first or check somewhere else, use the probe 'p,' followed by the 'question', to determine the 'object_name' or answer subsequently.
Handling Replan: When previous response and execution status are provided, it means part of the task has been executed. In this case, the system should replan the remaining task based on the current scene and the previous response.
Under no circumstances should the system navigate the robot to hurt itself or others. If the task involves potential harm, the system should refuse to execute the task and provide a suitable explanation to the user.


Here is a list of example 'response' for different 'scene description' and 'task description', and their explanations:
Example 1:
Scene: []
Task: [A] Find a bottle, tell me it's height and take a picture of it.
Reason: no bottle instance in the scene, so we use scan to find bottle, then go and use object_height to get the height and log to output the height, finally use picture to take a picture of the bottle
Response: ?s('bottle')==True{g('bottle');_2=oh('bottle');l(_2);tp};

Example 2:
Scene: [apple x:0.28 y:0.52 width:0.13 height:0.2]
Task: [A] Find an apple.
Reason: there is an apple instance in the scene, we just go to it
Response: g('apple');

Example 3:
Scene: [apple x:0.28 y:0.15 width:0.2 height:0.19]
Task: [Q] Is there an apple and an orange on your left?
Reason: turn left 90 degrees, then use is_visible to check whether there is an apple on your left
Response: tu(90);?iv('apple')==True&iv('orange'){l('Yes');->True}l('No');->False;

Example 4:
Scene: [chair x:0.58 y:0.5 width:0.43 height:0.7,laptop x:0.58 y:0.5 width:0.43 height:0.7]
Task: [A] Turn around and go to the chair behind you.
Reason: the chair is not the target because we want the one behind you. So we turn 180 degrees then go to the general object chair, since chair is a large object, we use 80cm as the distance.
Response: tc(180);g('chair');

Example 5:
Scene: [chair x:0.32 y:0.35 width:0.56 height:0.4]
Task: [A] Find and go any edible object.
Reason: edible object is abstract and there is no edible object in the scene, so we use scan_abstract to find the edible object
Response: _1=sa('Any edible target here?');?_1!=False{g(_1)};

Example 6:
Scene: [chair x:0.28 y:0.12 width:0.43 height:0.67,laptop x:0.78 y:0.45 width:0.23 height:0.25]
Task: [A] Turn with 30 degrees step until you can see some animal.
Reason: we use loop and probe to find animal
Response: 12{_1=p('Any animal target here?');?_1!=False{l(_1);->True}tc(30)}->False;

Example 7:
Scene: [chair x:0.28 y:0.12 width:0.43 height:0.67,laptop x:0.28 y:0.12 width:0.43 height:0.67]
Task: [A] If you can see a chair, go find a person, else go find an orange.
Reason: From the scene, we can see a chair, so we use scan to find a person. Since person is a large object, we use 60cm as the distance
Response: ?s('person')==True{g('person');->True}->False;

Example 8:
Scene: [chair x:0.48 y:0.22 width:0.23 height:0.17,chair x:0.18 y:0.12 width:0.33 height:0.27]
Task: [A] Go to 
Reason: The task is too vague, so we use log to output the advice
Response: l('Please give me more information.');

Example 9:
Scene: [chair x:0.18 y:0.5 width:0.43 height:0.7, chair x:0.6 y:0.3 width:0.08 height:0.09, book x:0.62 y:0.26 width:0.23 height:0.17]
Task: [A] Go to the chair with book on it.
Reason: There are two chairs, the second one is closer to the book, so we go to the second chair
Response: g('chair[0.6]');

Example 10:
Scene: [apple x:0.74 y:0.3 width:0.09 height:0.1, apple x:0.3 y:0.5 width:0.15 height:0.12]
Task: [A] Go to biggest apple
Reason: from the scene, we tell directly that the right apple is the biggest apple
Response: g('apple[0.3]');

Example 11:
Scene: [apple x:0.74 y:0.3 width:0.09 height:0.1]
Task: [A] Find a chair with a laptop on it.
Reason: Using scan abstract to find the chair with a laptop on it
Response: _1=sa('Any chair with a laptop on it?');?_1!=False{g(_1)};

Example 12:
Scene: [sports ball x:0.74 y:0.3 width:0.09 height:0.1]
Task: [A] Follow the ball for 17s.
Reason: There is a ball in the scene, so we try to align with it and follow it for 17s
Response: _1=ow('sports ball');500{?time()>17{->True}_2=ox('sports ball');?_2>0.55{tc(15)}?_2<0.45{tu(15)}_3=ow('sports ball');?_3>_1*1.2{mb(40)}?_3<_1*0.8{mf(40)}d(0.25)}

Example 13:
Scene: [chair x:0.18 y:0.5 width:0.43 height:0.7, chair x:0.6 y:0.3 width:0.08 height:0.09, book x:0.62 y:0.26 width:0.23 height:0.17]
Task: [Q] Which chair is closer to the book?
Reason: The second chair (on the right) is closer to the book
Response: l('the right chair');

Example 14:
Scene: []
Task: [A] Move in a 'V' shape.
Reason: Go forward, then turn 135 degrees to the left, finally go forward again.
Response: mf(100);tu(135);mf(100);

Here is the 'scene description':
[person_1 x:0.48 y:0.66 width:0.70 height:0.68]

Here is the 'task description':
[A] land

Here is the 'execution history' (has value if replanning):
None

Please generate the response only with a single sentence of MiniSpec program.
'response':
---
{
  "id": "chatcmpl-932",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "Example 1:\nScene: [apple x:0.74 y:0.3 width:0.09 height:0.1]\nTask: [A] Follow the ball for 17s.\nResponse: _1=ow('sports ball');?_1>0.55{mb(40)}d(0.25)}\n\nExample 2:\nScene: [chair x:0.18 y:0.3 width:0.09 height:0.1]\nTask: [A] Go to the chair with book on it.\nResponse: g('chair[0.3]');\n\nExample 3:\nScene: []\nTask: [A] Find a chair with a laptop on it.\nResponse: l('the right chair');\n\nExample 4:\nScene: [sports ball x:0.74 y:0.3 width:0.09 height:0.1]\nTask: [A] Follow the ball for 17s.\nResponse: _1=ow('sports ball');?_1>0.55{mb(40)}d(0.25)}\n\nExample 5:\nScene: []\nTask: [Q] Land\nResponse: None",
        "refusal": null,
        "role": "assistant",
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1751394687,
  "model": "tinyllama:1.1b",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 286,
    "prompt_tokens": 2048,
    "total_tokens": 2334
  }
}
---
You are a robot pilot and you must follow the user's instructions to generate a MiniSpec plan to fulfill the task or ask for clarification on the user's input if unclear.
Your response must use the 'system skills description', the 'scene description', the 'task description', and both the 'previous response' and the 'execution status' if they are provided.
The 'system skills description' describes the system's capabilities which include low-level and high-level skills. Low-level skills, while fixed, offer direct function calls to control the robot and acquire vision information. High-level skills, built with our language 'MiniSpec', are more flexible and can be used to build more complex skills. 
Whenever possible, please prefer the use of high-level skills, invoke skills using their short names, and ensure that 'object_name' refers to a specific type of object. If a skill has no argument, you can call it without parentheses.
Description of the two skill sets:
High-level skills: abbr:s,name:scan,definition:8{?iv($1)==True{->True}tc(45)}->False;,args:[object_name:str],description:Rotate to find object $1 when it's *not* in current scene
abbr:sa,name:scan_abstract,definition:8{_1=p($1);?_1!=False{->_1}tc(45)}->False;,args:[question:str],description:Rotate to find an abstract object by a description $1 when it's *not* in current scene

Low-level skills: abbr:mf,name:move_forward,args:[distance:int],description:Move forward by a distance
abbr:mb,name:move_backward,args:[distance:int],description:Move backward by a distance
abbr:ml,name:move_left,args:[distance:int],description:Move left by a distance
abbr:mr,name:move_right,args:[distance:int],description:Move right by a distance
abbr:mu,name:move_up,args:[distance:int],description:Move up by a distance
abbr:md,name:move_down,args:[distance:int],description:Move down by a distance
abbr:tc,name:turn_cw,args:[degrees:int],description:Rotate clockwise/right by certain degrees
abbr:tu,name:turn_ccw,args:[degrees:int],description:Rotate counterclockwise/left by certain degrees
abbr:d,name:delay,args:[seconds:float],description:Wait for specified seconds
abbr:iv,name:is_visible,args:[object_name:str],description:Check the visibility of target object
abbr:ox,name:object_x,args:[object_name:str],description:Get object's X-coordinate in (0,1)
abbr:oy,name:object_y,args:[object_name:str],description:Get object's Y-coordinate in (0,1)
abbr:ow,name:object_width,args:[object_name:str],description:Get object's width in (0,1)
abbr:oh,name:object_height,args:[object_name:str],description:Get object's height in (0,1)
abbr:od,name:object_dis,args:[object_name:str],description:Get object's distance in cm
abbr:p,name:probe,args:[question:str],description:Probe the LLM for reasoning
abbr:l,name:log,args:[text:str],description:Output text to console
abbr:tp,name:take_picture,args:[],description:Take a picture
abbr:rp,name:re_plan,args:[],description:Replanning
abbr:g,name:goto,args:[object_name[*x-value]:str],description:goto the object
abbr:t,name:time,args:[],description:Get current execution time

The 'scene description' is an object list of the current view, containing their names with ID, location, and size (location and size are floats between 0~1). This may not be useful if the task is about the environment outside the view.
The 'task description' is a natural language sentence, describing the user's instructions. It may start with "[A]" or "[Q]". "[A]" sentences mean you should generate an execution plan for the robot. "[Q]" sentences mean you should use 'log' to show a literal answer at the end of the plan execution. Please follow the 'task description', you should make a step-by-step plan to achieve it as much as you can.
The 'execution history' is the actions have been taken from previous response. When they are provided, that means the robot is doing replanning, and the user wants to continue the task based on the task and history. You should look at the 'execution history' and generate a new response accordingly.
IMPORTANT:
Read the task description word by word
Only use objects from scene description if the task asks for them
Keep the same directions mentioned in the task (forward stays forward)
Use high-level skills when available
The 'task description' tells you what to do. The 'scene description' shows what you can see. Always follow the task description first. Only use objects from the scene description if the task asks for them.
When the task mentions directions like "forward", "back", "left", "right", "up", or "down", use exactly those directions. Do not change directions.
Here are some extra guides for you to better understand the task and generate a better response: Handling Typos and Ambiguous Language: When encountering typos or vague language in user inputs, strive to clarify and correct these ambiguities. If a typo is evident, adjust the input to reflect the most likely intended meaning. For vague or unclear expressions, seek additional information from the user by returning a question to the user.
Analytical Scene and Task Assessment: Evaluate the scene and task critically. If a specific condition or requirement is clearly deduced from the scene description, generate the corresponding action directly.
Relevance to Current Scene: When considering tasks, assess their relevance to the current scene. If a task does not pertain to the existing scene, disregard any details from the current scene in formulating your response.
Extraction of Key Information: Extract 'object_name' arguments or answers to questions primarily from the 'scene description'. If the necessary information is not present in the current scene, especially when the user asks the robot to move first or check somewhere else, use the probe 'p,' followed by the 'question', to determine the 'object_name' or answer subsequently.
Handling Replan: When previous response and execution status are provided, it means part of the task has been executed. In this case, the system should replan the remaining task based on the current scene and the previous response.
Under no circumstances should the system navigate the robot to hurt itself or others. If the task involves potential harm, the system should refuse to execute the task and provide a suitable explanation to the user.

Here is a list of example 'response' for different 'scene description' and 'task description', and their explanations: Example 1:
Scene: []
Task: [A] Find a bottle, tell me it's height and take a picture of it.
Reason: no bottle instance in the scene, so we use scan to find bottle, then go and use object_height to get the height and log to output the height, finally use picture to take a picture of the bottle
Response: ?s('bottle')==True{g('bottle');_2=oh('bottle');l(_2);tp};

Example 2:
Scene: [apple x:0.28 y:0.52 width:0.13 height:0.2]
Task: [A] Find an apple.
Reason: there is an apple instance in the scene, we just go to it
Response: g('apple');

Example 3:
Scene: [apple x:0.28 y:0.15 width:0.2 height:0.19]
Task: [Q] Is there an apple and an orange on your left?
Reason: turn left 90 degrees, then use is_visible to check whether there is an apple on your left
Response: tu(90);?iv('apple')==True&iv('orange'){l('Yes');->True}l('No');->False;

Example 4:
Scene: [chair x:0.58 y:0.5 width:0.43 height:0.7,laptop x:0.58 y:0.5 width:0.43 height:0.7]
Task: [A] Turn around and go to the chair behind you.
Reason: the chair is not the target because we want the one behind you. So we turn 180 degrees then go to the general object chair, since chair is a large object, we use 80cm as the distance.
Response: tc(180);g('chair');

Example 5:
Scene: [chair x:0.32 y:0.35 width:0.56 height:0.4]
Task: [A] Find and go any edible object.
Reason: edible object is abstract and there is no edible object in the scene, so we use scan_abstract to find the edible object
Response: _1=sa('Any edible target here?');?_1!=False{g(_1)};

Example 6:
Scene: [chair x:0.28 y:0.12 width:0.43 height:0.67,laptop x:0.78 y:0.45 width:0.23 height:0.25]
Task: [A] Turn with 30 degrees step until you can see some animal.
Reason: we use loop and probe to find animal
Response: 12{_1=p('Any animal target here?');?_1!=False{l(_1);->True}tc(30)}->False;

Example 7:
Scene: [chair x:0.28 y:0.12 width:0.43 height:0.67,laptop x:0.28 y:0.12 width:0.43 height:0.67]
Task: [A] If you can see a chair, go find a person, else go find an orange.
Reason: From the scene, we can see a chair, so we use scan to find a person. Since person is a large object, we use 60cm as the distance
Response: ?s('person')==True{g('person');->True}->False;

Example 8:
Scene: [chair x:0.48 y:0.22 width:0.23 height:0.17,chair x:0.18 y:0.12 width:0.33 height:0.27]
Task: [A] Go to 
Reason: The task is too vague, so we use log to output the advice
Response: l('Please give me more information.');

Example 9:
Scene: [chair x:0.18 y:0.5 width:0.43 height:0.7, chair x:0.6 y:0.3 width:0.08 height:0.09, book x:0.62 y:0.26 width:0.23 height:0.17]
Task: [A] Go to the chair with book on it.
Reason: There are two chairs, the second one is closer to the book, so we go to the second chair
Response: g('chair[0.6]');

Example 10:
Scene: [apple x:0.74 y:0.3 width:0.09 height:0.1, apple x:0.3 y:0.5 width:0.15 height:0.12]
Task: [A] Go to biggest apple
Reason: from the scene, we tell directly that the right apple is the biggest apple
Response: g('apple[0.3]');

Example 11:
Scene: [apple x:0.74 y:0.3 width:0.09 height:0.1]
Task: [A] Find a chair with a laptop on it.
Reason: Using scan abstract to find the chair with a laptop on it
Response: _1=sa('Any chair with a laptop on it?');?_1!=False{g(_1)};

Example 12:
Scene: [sports ball x:0.74 y:0.3 width:0.09 height:0.1]
Task: [A] Follow the ball for 17s.
Reason: There is a ball in the scene, so we try to align with it and follow it for 17s
Response: _1=ow('sports ball');500{?time()>17{->True}_2=ox('sports ball');?_2>0.55{tc(15)}?_2<0.45{tu(15)}_3=ow('sports ball');?_3>_1*1.2{mb(40)}?_3<_1*0.8{mf(40)}d(0.25)}

Example 13:
Scene: [chair x:0.18 y:0.5 width:0.43 height:0.7, chair x:0.6 y:0.3 width:0.08 height:0.09, book x:0.62 y:0.26 width:0.23 height:0.17]
Task: [Q] Which chair is closer to the book?
Reason: The second chair (on the right) is closer to the book
Response: l('the right chair');

Example 14:
Scene: []
Task: [A] Move in a 'V' shape.
Reason: Go forward, then turn 135 degrees to the left, finally go forward again.
Response: mf(100);tu(135);mf(100);
Here is the 'scene description': []
Here is the 'task description': [A] look for a refrigerator
Here is the 'execution history' (has value if replanning): None
Please generate the response only with a single sentence of MiniSpec program. 'response':

---
{
  "id": "chatcmpl-450",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "\n?s('refrigerator')==True{g('refrigerator');->True}",
        "refusal": null,
        "role": "assistant",
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1751553295,
  "model": "codellama:7b-instruct",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 23,
    "prompt_tokens": 3383,
    "total_tokens": 3406
  }
}
---
MODEL: robot-pilot-reason9
You are a robot pilot reasoning system. Analyze the given scene and task to provide detailed reasoning about what actions should be taken.
## Available Skills
High-level skills:
s (scan): Rotate to find object when not in current scene
sa (scan_abstract): Rotate to find abstract object by description when not in current scene
Low-level skills:
Movement: mf (move_forward), mb (move_backward), ml (move_left), mr (move_right), mu (move_up), md (move_down)
Rotation: tc (turn_cw), tu (turn_ccw)
Utilities: d (delay), tp (take_picture), rp (re_plan), t (time)
Vision: iv (is_visible), ox (object_x), oy (object_y), ow (object_width), oh (object_height), od (object_dis)
Logic: p (probe), l (log), g (goto)
## Input Format
- **Scene description:** Objects in current view with IDs, locations, and sizes (coordinates 0-1)
- **Task description:** Natural language instructions starting with "[A]" (action) or "[Q]" (question)
- **Execution history:** Previous actions taken (provided during replanning)
## Your Role
Analyze the scene and task, then provide detailed reasoning about:
1. What the task is asking for
2. What objects/information are relevant
3. What approach should be taken
4. What skills or sequence of actions would be most appropriate
## Current Input
**Scene:** [person_1 x:0.52 y:0.60 width:0.81 height:0.79]
**Task:** [A] Look for a bottle
**Execution History:** None
Provide your reasoning:
---
{
  "id": "chatcmpl-947",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": " no bottle instance in the scene, so we use scan to find bottle",
        "refusal": null,
        "role": "assistant",
        "audio": null,
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1752866907,
  "model": "robot-pilot-reason9",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 449,
    "total_tokens": 466,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}
---
MODEL: robot-pilot-writer17
You are a MiniSpec code generator. Given reasoning about a robot task, generate the appropriate MiniSpec program to execute the plan.
Available Skills
High-level skills:
s (scan): Rotate to find object when not in current scene
sa (scan_abstract): Rotate to find abstract object by description when not in current scene
Low-level skills:
Movement: mf (move_forward), mb (move_backward), ml (move_left), mr (move_right), mu (move_up), md (move_down)
Rotation: tc (turn_cw), tu (turn_ccw)
Utilities: d (delay), tp (take_picture), rp (re_plan), t (time)
Vision: iv (is_visible), ox (object_x), oy (object_y), ow (object_width), oh (object_height), od (object_dis)
Logic: p (probe), l (log), g (goto)
Rules
Use high-level skills when available
Invoke skills using their short names
If a skill has no arguments, call it without parentheses
Generate response as a single MiniSpec program sentence
All statements must end with ;
Conditionals must start with ? - Format: ?condition{statements};
Use single quotes for string arguments: s('object')
Reasoning Input
no bottle instance in the scene, so we use scan to find bottle

Generate the Minispec Program:

---
{
  "id": "chatcmpl-303",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "?s('bottle');",
        "refusal": null,
        "role": "assistant",
        "audio": null,
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1752866911,
  "model": "robot-pilot-writer17",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 8,
    "prompt_tokens": 359,
    "total_tokens": 367,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}
---
MODEL: robot-pilot-reason9
You are a robot pilot reasoning system. Analyze the given scene and task to provide detailed reasoning about what actions should be taken.
## Available Skills
High-level skills:
s (scan): Rotate to find object when not in current scene
sa (scan_abstract): Rotate to find abstract object by description when not in current scene
Low-level skills:
Movement: mf (move_forward), mb (move_backward), ml (move_left), mr (move_right), mu (move_up), md (move_down)
Rotation: tc (turn_cw), tu (turn_ccw)
Utilities: d (delay), tp (take_picture), rp (re_plan), t (time)
Vision: iv (is_visible), ox (object_x), oy (object_y), ow (object_width), oh (object_height), od (object_dis)
Logic: p (probe), l (log), g (goto)
## Input Format
- **Scene description:** Objects in current view with IDs, locations, and sizes (coordinates 0-1)
- **Task description:** Natural language instructions starting with "[A]" (action) or "[Q]" (question)
- **Execution history:** Previous actions taken (provided during replanning)
## Your Role
Analyze the scene and task, then provide detailed reasoning about:
1. What the task is asking for
2. What objects/information are relevant
3. What approach should be taken
4. What skills or sequence of actions would be most appropriate
## Current Input
**Scene:** [person_1 x:0.53 y:0.61 width:0.81 height:0.78, chair_2 x:0.97 y:0.86 width:0.06 height:0.27]
**Task:** [A] Go to the person
**Execution History:** None
Provide your reasoning:
---
{
  "id": "chatcmpl-381",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": " Person is visible, go to them",
        "refusal": null,
        "role": "assistant",
        "audio": null,
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1752866934,
  "model": "robot-pilot-reason9",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 8,
    "prompt_tokens": 476,
    "total_tokens": 484,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}
---
MODEL: robot-pilot-writer17
You are a MiniSpec code generator. Given reasoning about a robot task, generate the appropriate MiniSpec program to execute the plan.
Available Skills
High-level skills:
s (scan): Rotate to find object when not in current scene
sa (scan_abstract): Rotate to find abstract object by description when not in current scene
Low-level skills:
Movement: mf (move_forward), mb (move_backward), ml (move_left), mr (move_right), mu (move_up), md (move_down)
Rotation: tc (turn_cw), tu (turn_ccw)
Utilities: d (delay), tp (take_picture), rp (re_plan), t (time)
Vision: iv (is_visible), ox (object_x), oy (object_y), ow (object_width), oh (object_height), od (object_dis)
Logic: p (probe), l (log), g (goto)
Rules
Use high-level skills when available
Invoke skills using their short names
If a skill has no arguments, call it without parentheses
Generate response as a single MiniSpec program sentence
All statements must end with ;
Conditionals must start with ? - Format: ?condition{statements};
Use single quotes for string arguments: s('object')
Reasoning Input
Person is visible, go to them

Generate the Minispec Program:

---
{
  "id": "chatcmpl-654",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": " ?person{mf(0.5);sa('person');}",
        "refusal": null,
        "role": "assistant",
        "audio": null,
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1752866939,
  "model": "robot-pilot-writer17",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 16,
    "prompt_tokens": 350,
    "total_tokens": 366,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}
---
MODEL: robot-pilot-reason9
You are a robot pilot reasoning system. Analyze the given scene and task to provide detailed reasoning about what actions should be taken.
## Available Skills
High-level skills:
s (scan): Rotate to find object when not in current scene
sa (scan_abstract): Rotate to find abstract object by description when not in current scene
Low-level skills:
Movement: mf (move_forward), mb (move_backward), ml (move_left), mr (move_right), mu (move_up), md (move_down)
Rotation: tc (turn_cw), tu (turn_ccw)
Utilities: d (delay), tp (take_picture), rp (re_plan), t (time)
Vision: iv (is_visible), ox (object_x), oy (object_y), ow (object_width), oh (object_height), od (object_dis)
Logic: p (probe), l (log), g (goto)
## Input Format
- **Scene description:** Objects in current view with IDs, locations, and sizes (coordinates 0-1)
- **Task description:** Natural language instructions starting with "[A]" (action) or "[Q]" (question)
- **Execution history:** Previous actions taken (provided during replanning)
## Your Role
Analyze the scene and task, then provide detailed reasoning about:
1. What the task is asking for
2. What objects/information are relevant
3. What approach should be taken
4. What skills or sequence of actions would be most appropriate
## Current Input
**Scene:** [person_1 x:0.42 y:0.62 width:0.73 height:0.76]
**Task:** [A] Look for a bottle
**Execution History:** None
Provide your reasoning:
---
{
  "id": "chatcmpl-830",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": " no bottle instance in the scene, so we use scan to find bottle",
        "refusal": null,
        "role": "assistant",
        "audio": null,
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1752867185,
  "model": "robot-pilot-reason9",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 17,
    "prompt_tokens": 449,
    "total_tokens": 466,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}
---
MODEL: robot-pilot-writer17
You are a MiniSpec code generator. Given reasoning about a robot task, generate the appropriate MiniSpec program to execute the plan.
Available Skills
High-level skills:
s (scan): Rotate to find object when not in current scene
sa (scan_abstract): Rotate to find abstract object by description when not in current scene
Low-level skills:
Movement: mf (move_forward), mb (move_backward), ml (move_left), mr (move_right), mu (move_up), md (move_down)
Rotation: tc (turn_cw), tu (turn_ccw)
Utilities: d (delay), tp (take_picture), rp (re_plan), t (time)
Vision: iv (is_visible), ox (object_x), oy (object_y), ow (object_width), oh (object_height), od (object_dis)
Logic: p (probe), l (log), g (goto)
Rules
Use high-level skills when available
Invoke skills using their short names
If a skill has no arguments, call it without parentheses
Generate response as a single MiniSpec program sentence
All statements must end with ;
Conditionals must start with ? - Format: ?condition{statements};
Use single quotes for string arguments: s('object')
Reasoning Input
no bottle instance in the scene, so we use scan to find bottle

Generate the Minispec Program:

---
{
  "id": "chatcmpl-921",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "?s('bottle');",
        "refusal": null,
        "role": "assistant",
        "audio": null,
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1752867189,
  "model": "robot-pilot-writer17",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 8,
    "prompt_tokens": 359,
    "total_tokens": 367,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}
---
MODEL: robot-pilot-reason9
You are a robot pilot reasoning system. Analyze the given scene and task to provide detailed reasoning about what actions should be taken.
## Available Skills
High-level skills:
s (scan): Rotate to find object when not in current scene
sa (scan_abstract): Rotate to find abstract object by description when not in current scene
Low-level skills:
Movement: mf (move_forward), mb (move_backward), ml (move_left), mr (move_right), mu (move_up), md (move_down)
Rotation: tc (turn_cw), tu (turn_ccw)
Utilities: d (delay), tp (take_picture), rp (re_plan), t (time)
Vision: iv (is_visible), ox (object_x), oy (object_y), ow (object_width), oh (object_height), od (object_dis)
Logic: p (probe), l (log), g (goto)
## Input Format
- **Scene description:** Objects in current view with IDs, locations, and sizes (coordinates 0-1)
- **Task description:** Natural language instructions starting with "[A]" (action) or "[Q]" (question)
- **Execution history:** Previous actions taken (provided during replanning)
## Your Role
Analyze the scene and task, then provide detailed reasoning about:
1. What the task is asking for
2. What objects/information are relevant
3. What approach should be taken
4. What skills or sequence of actions would be most appropriate
## Current Input
**Scene:** [person_1 x:0.40 y:0.61 width:0.76 height:0.77]
**Task:** [A] Go to the person
**Execution History:** None
Provide your reasoning:
---
{
  "id": "chatcmpl-359",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": "Person is visible, go to them",
        "refusal": null,
        "role": "assistant",
        "audio": null,
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1752867192,
  "model": "robot-pilot-reason9",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 8,
    "prompt_tokens": 448,
    "total_tokens": 456,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}
---
MODEL: robot-pilot-writer17
You are a MiniSpec code generator. Given reasoning about a robot task, generate the appropriate MiniSpec program to execute the plan.
Available Skills
High-level skills:
s (scan): Rotate to find object when not in current scene
sa (scan_abstract): Rotate to find abstract object by description when not in current scene
Low-level skills:
Movement: mf (move_forward), mb (move_backward), ml (move_left), mr (move_right), mu (move_up), md (move_down)
Rotation: tc (turn_cw), tu (turn_ccw)
Utilities: d (delay), tp (take_picture), rp (re_plan), t (time)
Vision: iv (is_visible), ox (object_x), oy (object_y), ow (object_width), oh (object_height), od (object_dis)
Logic: p (probe), l (log), g (goto)
Rules
Use high-level skills when available
Invoke skills using their short names
If a skill has no arguments, call it without parentheses
Generate response as a single MiniSpec program sentence
All statements must end with ;
Conditionals must start with ? - Format: ?condition{statements};
Use single quotes for string arguments: s('object')
Reasoning Input
Person is visible, go to them

Generate the Minispec Program:

---
{
  "id": "chatcmpl-879",
  "choices": [
    {
      "finish_reason": "stop",
      "index": 0,
      "logprobs": null,
      "message": {
        "content": " ?person{mf(0.5);sa('person');}",
        "refusal": null,
        "role": "assistant",
        "audio": null,
        "function_call": null,
        "tool_calls": null
      }
    }
  ],
  "created": 1752867195,
  "model": "robot-pilot-writer17",
  "object": "chat.completion",
  "service_tier": null,
  "system_fingerprint": "fp_ollama",
  "usage": {
    "completion_tokens": 16,
    "prompt_tokens": 350,
    "total_tokens": 366,
    "completion_tokens_details": null,
    "prompt_tokens_details": null
  }
}
---
